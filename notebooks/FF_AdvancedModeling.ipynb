{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advanced Modeling**\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building upon the insights gained from the baseline modeling phase, this notebook focuses on advancing the predictive capabilities of our NFL fantasy points model by leveraging gradient boosting. Gradient boosting models, known for their robustness and ability to capture non-linear relationships, should be well-suited for handling the complexities and variability inherent in player performance data.\n",
    "\n",
    "**Objectives**\n",
    "\n",
    "- Develop advanced models for predicting fantasy points across different positions (e.g., QB, RB, WR, TE)\n",
    "\n",
    "- Implement Gradient Boosting to enhance predictive performance\n",
    "\n",
    "- Evaluate the impact of ensemble methods in capturing the positional nuances identified in the baseline models\n",
    "\n",
    "**Key Advancements Over Baseline Models**\n",
    "\n",
    "- Non-linear Modeling: Unlike linear regression, Gradient Boosting can naturally handle non-linear patterns, which are prevalent in sports performance metrics\n",
    "\n",
    "- Feature Interactions: Ensemble methods inherently capture complex interactions between cumulative metrics, rolling averages, and other features\n",
    "\n",
    "- Position-Specific Insights: Utilizing Gradient Boosting for each position should provide deeper insights into the key predictors for each position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting**\n",
    "- \n",
    "\n",
    "Gradient Boosting is a machine learning technique that builds predictive models in an iterative method by combining multiple weak learners to form a strong learner. \"Boosting\" refers to the sequential process of improving the model by minimizing the errors of previous models. Gradient boosting algorithms will be used to model player performance as they excel at working with small to medium datasets by fine-tuning errors iteratively. They also typically outperform linear regression models (such as the baseline model) because gradient boosting captures non-linear relationships between features and the target variable, whereas linear regression assumes a strictly linear relationship. Player statistics and fantasy points have complex, sometimes non-linear interactions, potentially making gradient boosting a better fit. Gradient boosting can also model complex relationships between features and outcomes effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries/Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll = pd.read_csv(\"/Users/mychalortiz/Downloads/Brainstation/FantasyForecasts/notebooks/ModelingDataframes/dfAll.csv\")\n",
    "qbsM = pd.read_csv(\"/Users/mychalortiz/Downloads/Brainstation/FantasyForecasts/notebooks/ModelingDataframes/qbsM.csv\")\n",
    "rbsM = pd.read_csv(\"/Users/mychalortiz/Downloads/Brainstation/FantasyForecasts/notebooks/ModelingDataframes/rbsM.csv\")\n",
    "wrsM = pd.read_csv(\"/Users/mychalortiz/Downloads/Brainstation/FantasyForecasts/notebooks/ModelingDataframes/wrsM.csv\")\n",
    "tesM = pd.read_csv(\"/Users/mychalortiz/Downloads/Brainstation/FantasyForecasts/notebooks/ModelingDataframes/tesM.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PLAYER NAME</th>\n",
       "      <th>PLAYER TEAM</th>\n",
       "      <th>PLAYER POSITION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>Location</th>\n",
       "      <th>rank</th>\n",
       "      <th>DATE</th>\n",
       "      <th>...</th>\n",
       "      <th>season_rushing_td</th>\n",
       "      <th>season_total_avg</th>\n",
       "      <th>season_passing_yds_avg</th>\n",
       "      <th>season_passing_td_avg</th>\n",
       "      <th>season_receiving_rec_avg</th>\n",
       "      <th>season_receiving_yds_avg</th>\n",
       "      <th>season_receiving_td_avg</th>\n",
       "      <th>season_rushing_car_avg</th>\n",
       "      <th>season_rushing_yds_avg</th>\n",
       "      <th>season_fantasy_points_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>335</td>\n",
       "      <td>AJ McCarron</td>\n",
       "      <td>Cin</td>\n",
       "      <td>QB</td>\n",
       "      <td>W 31-14</td>\n",
       "      <td>0.80</td>\n",
       "      <td>Cle</td>\n",
       "      <td>Home</td>\n",
       "      <td>34.0</td>\n",
       "      <td>01-09-24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300</td>\n",
       "      <td>AJ McCarron</td>\n",
       "      <td>Cin</td>\n",
       "      <td>QB</td>\n",
       "      <td>W 34-14</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>Ind</td>\n",
       "      <td>Home</td>\n",
       "      <td>38.0</td>\n",
       "      <td>12-12-23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>NYJ</td>\n",
       "      <td>QB</td>\n",
       "      <td>W 22-16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Buf</td>\n",
       "      <td>Home</td>\n",
       "      <td>36.0</td>\n",
       "      <td>09-12-23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>468</td>\n",
       "      <td>Aidan O'Connell</td>\n",
       "      <td>LV</td>\n",
       "      <td>QB</td>\n",
       "      <td>L 20-23</td>\n",
       "      <td>20.26</td>\n",
       "      <td>Ind</td>\n",
       "      <td>Away</td>\n",
       "      <td>9.0</td>\n",
       "      <td>01-02-24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.26</td>\n",
       "      <td>299.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312</td>\n",
       "      <td>Aidan O'Connell</td>\n",
       "      <td>LV</td>\n",
       "      <td>QB</td>\n",
       "      <td>W 27-14</td>\n",
       "      <td>17.86</td>\n",
       "      <td>Den</td>\n",
       "      <td>Home</td>\n",
       "      <td>11.0</td>\n",
       "      <td>01-09-24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.06</td>\n",
       "      <td>271.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      PLAYER NAME PLAYER TEAM PLAYER POSITION   STATUS  TOTAL  \\\n",
       "0         335      AJ McCarron         Cin              QB  W 31-14   0.80   \n",
       "1         300      AJ McCarron         Cin              QB  W 34-14  -0.04   \n",
       "2          75    Aaron Rodgers         NYJ              QB  W 22-16   0.00   \n",
       "3         468  Aidan O'Connell          LV              QB  L 20-23  20.26   \n",
       "4         312  Aidan O'Connell          LV              QB  W 27-14  17.86   \n",
       "\n",
       "  Opponent Location  rank      DATE  ...  season_rushing_td  season_total_avg  \\\n",
       "0      Cle     Home  34.0  01-09-24  ...                0.0              0.80   \n",
       "1      Ind     Home  38.0  12-12-23  ...                0.0              0.38   \n",
       "2      Buf     Home  36.0  09-12-23  ...                0.0              0.00   \n",
       "3      Ind     Away   9.0  01-02-24  ...                0.0             20.26   \n",
       "4      Den     Home  11.0  01-09-24  ...                0.0             19.06   \n",
       "\n",
       "   season_passing_yds_avg  season_passing_td_avg  season_receiving_rec_avg  \\\n",
       "0                    20.0                    0.0                       0.0   \n",
       "1                     9.5                    0.0                       0.0   \n",
       "2                     0.0                    0.0                       0.0   \n",
       "3                   299.0                    2.0                       0.0   \n",
       "4                   271.5                    2.0                       0.0   \n",
       "\n",
       "   season_receiving_yds_avg  season_receiving_td_avg  season_rushing_car_avg  \\\n",
       "0                       0.0                      0.0                     0.0   \n",
       "1                       0.0                      0.0                     0.0   \n",
       "2                       0.0                      0.0                     0.0   \n",
       "3                       0.0                      0.0                     2.0   \n",
       "4                       0.0                      0.0                     3.0   \n",
       "\n",
       "   season_rushing_yds_avg  season_fantasy_points_avg  \n",
       "0                     0.0                       0.80  \n",
       "1                     0.0                       0.38  \n",
       "2                     0.0                       0.00  \n",
       "3                     3.0                      20.26  \n",
       "4                     2.0                      19.06  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qbsM.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ensuring DataFrames have been transfered correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Pipeline**\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('imputer', SimpleImputer()),  \n",
    "    #handles missing values\n",
    "    ('model', GradientBoostingRegressor()) \n",
    "    #model being used\n",
    "]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "paramGrid = {'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "             'model__n_estimators': [100, 200, 500],\n",
    "             'model__max_depth': [3, 5, 7],\n",
    "             'model__min_samples_split': [2, 5, 10], \n",
    "             'model__min_samples_leaf': [1, 3, 5],    \n",
    "             'model__subsample': [0.8, 1.0],          \n",
    "             'imputer__strategy': ['mean', 'median', 'most_frequent', 'constant']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline Architecture**\n",
    "- \n",
    "\n",
    "A pipeline is used to combine multiple processing steps into a single workflow, ensuring consistency and reproducibility while simplifying hyperparameter tuning.\n",
    "\n",
    "**Hyperparameters**\n",
    "- Learning Rate:\n",
    "    - Controls the step size at each iteration while minimizing the loss\n",
    "    - Smaller values allow for a more fine-grained optimization, which reduces the risk of overfitting\n",
    "    - Suitable for the dataset, since predictions involve subtle relationships between variables\n",
    "- Number of Estimators:\n",
    "    - Determines the number of boosting rounds (trees) to build\n",
    "    - A higher number of trees generally improves accuracy but increases the risk of overfitting\n",
    "- Maximum Depth:\n",
    "    - Controls the depth of each tree, limiting its complexity\n",
    "    - Shallow trees help prevent overfitting but may miss complex patterns in player performance\n",
    "    - Deeper trees can capture intricate interactions, which is important in the context of NFL data where player performance depends on various different factors\n",
    "- Minimum Samples Split:\n",
    "    - Specifies the minimum number of samples required to split an internal node\n",
    "    - Larger values prevent the model from learning overly specific splits, which reduces overfitting\n",
    "    - Smaller values allow the model to capture more specific patterns in the data, which might be useful for rare interactions in player performance\n",
    "- Minimum Samples Leaf:\n",
    "    - Specifies the minimum number of samples required to be in a leaf node\n",
    "    - Larger values result in smoother predictions and reduce overfitting by ensuring splits aren't based on small, possibly noisy samples\n",
    "    - Smaller values allow the model to capture more granular patterns, which can be beneficial for capturing outlier performances\n",
    "- Subsample:\n",
    "    - Specifies the fraction of the training data used for each tree\n",
    "    - Helps in reducing overfitting by introducing randomness\n",
    "    - Values like 0.8 and 1.0 ensure trees are trained on sufficient but not identical data\n",
    "- Imputer Strategy\n",
    "    - Specifies the strategy used for imputing values\n",
    "    - Options include mean, median, most frequent, and constant\n",
    "\n",
    "**Estimators**\n",
    "- Imputer:\n",
    "    - Handles missing values in the dataset by replacing them with specified strategies (mean, median, most frequent, and constant)\n",
    "- GradientBoostingRegressor:\n",
    "    - Tradtional gradient boosting\n",
    "\n",
    "**Workflow**\n",
    "- \n",
    "1. The imputer processes the data to handle missing values based on the specified strategy.\n",
    "2. The preprocessed data is passed to the Gradient Boosting Regressor, which learns patterns based on the training data.\n",
    "3. The hyperparameter grid is used with grid search cross validation to identify the best combination of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quarterback Gradient Boosting Model**\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a gradient boosting model to predict fantasy points for quarterbacks. The first iteration will be built manually, and the second iteration will use 5-fold grid search cross validation in order to optimize hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>Week</th>\n",
       "      <th>did_not_play</th>\n",
       "      <th>Name_Encoded</th>\n",
       "      <th>Team_Encoded</th>\n",
       "      <th>Opponent_Encoded</th>\n",
       "      <th>Home/Away_Encoded</th>\n",
       "      <th>total_5_game_avg</th>\n",
       "      <th>passing_yds_5_game_avg</th>\n",
       "      <th>passing_td_5_game_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>season_rushing_td</th>\n",
       "      <th>season_total_avg</th>\n",
       "      <th>season_passing_yds_avg</th>\n",
       "      <th>season_passing_td_avg</th>\n",
       "      <th>season_receiving_rec_avg</th>\n",
       "      <th>season_receiving_yds_avg</th>\n",
       "      <th>season_receiving_td_avg</th>\n",
       "      <th>season_rushing_car_avg</th>\n",
       "      <th>season_rushing_yds_avg</th>\n",
       "      <th>season_fantasy_points_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>20.26</td>\n",
       "      <td>299.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.26</td>\n",
       "      <td>299.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>19.06</td>\n",
       "      <td>271.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.06</td>\n",
       "      <td>271.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank  Week  did_not_play  Name_Encoded  Team_Encoded  Opponent_Encoded  \\\n",
       "0  34.0    18             0             0             6                 7   \n",
       "1  38.0    14             0             0             6                13   \n",
       "2  36.0     1             0             1            24                 3   \n",
       "3   9.0    17             0             2            18                13   \n",
       "4  11.0    18             0             2            18                 9   \n",
       "\n",
       "   Home/Away_Encoded  total_5_game_avg  passing_yds_5_game_avg  \\\n",
       "0                  1              0.80                    20.0   \n",
       "1                  1              0.38                     9.5   \n",
       "2                  1              0.00                     0.0   \n",
       "3                  0             20.26                   299.0   \n",
       "4                  1             19.06                   271.5   \n",
       "\n",
       "   passing_td_5_game_avg  ...  season_rushing_td  season_total_avg  \\\n",
       "0                    0.0  ...                0.0              0.80   \n",
       "1                    0.0  ...                0.0              0.38   \n",
       "2                    0.0  ...                0.0              0.00   \n",
       "3                    2.0  ...                0.0             20.26   \n",
       "4                    2.0  ...                0.0             19.06   \n",
       "\n",
       "   season_passing_yds_avg  season_passing_td_avg  season_receiving_rec_avg  \\\n",
       "0                    20.0                    0.0                       0.0   \n",
       "1                     9.5                    0.0                       0.0   \n",
       "2                     0.0                    0.0                       0.0   \n",
       "3                   299.0                    2.0                       0.0   \n",
       "4                   271.5                    2.0                       0.0   \n",
       "\n",
       "   season_receiving_yds_avg  season_receiving_td_avg  season_rushing_car_avg  \\\n",
       "0                       0.0                      0.0                     0.0   \n",
       "1                       0.0                      0.0                     0.0   \n",
       "2                       0.0                      0.0                     0.0   \n",
       "3                       0.0                      0.0                     2.0   \n",
       "4                       0.0                      0.0                     3.0   \n",
       "\n",
       "   season_rushing_yds_avg  season_fantasy_points_avg  \n",
       "0                     0.0                       0.80  \n",
       "1                     0.0                       0.38  \n",
       "2                     0.0                       0.00  \n",
       "3                     3.0                      20.26  \n",
       "4                     2.0                      19.06  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xqb = qbsM.select_dtypes(include = 'number').drop(columns=['TOTAL', 'Unnamed: 0'])\n",
    "\n",
    "yqb = qbsM['TOTAL']\n",
    "#assigning X and y\n",
    "\n",
    "Xqb.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assigning independent and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainQB, X_testQB, y_trainQB, y_testQB = train_test_split(Xqb, yqb, test_size= .80, random_state = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splitting up the data and allocating 80% of it to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***1st Iteration (not using hyperparameter tuning or grid search cross validation)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.8115647605939482\n",
      "R-squared: 0.920190963394392\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "#initializing the gradient boosting regressor\n",
    "\n",
    "model.fit(X_trainQB, y_trainQB)\n",
    "#fitting the model to the training data\n",
    "\n",
    "y_predQB = model.predict(X_testQB)\n",
    "#getting prediction on the test set\n",
    "\n",
    "mae = mean_absolute_error(y_testQB, y_predQB)\n",
    "r2 = r2_score(y_testQB, y_predQB)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "#getting prediction metrics on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fitting/testing the model manually (without hyperparameter tuning or grid search cross validation)\n",
    "- Parameters\n",
    "    - Number of estimators: 100\n",
    "    - Learning rate: 0.1\n",
    "    - Max Depth: 3\n",
    "- R-Squared\n",
    "    - Good value of 0.92, meaning ~92% of the variance in the data is explained by the model\n",
    "    - Indicates good understanding of the variance, without indicating overfitting\n",
    "- Mean Absolute Error\n",
    "    - Good value of 1.8\n",
    "    - On average, the models predictions are off by ~1.8 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2nd Iteration (using hyperparameter tuning and grid search cross validation)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'imputer__strategy': 'mean', 'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 5, 'model__min_samples_split': 2, 'model__n_estimators': 500, 'model__subsample': 0.8}\n",
      "R-squared: 0.9241721510896314\n",
      "Mean Absolute Error (MAE): 1.819497914233167\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipe, paramGrid, cv=5, scoring='neg_mean_squared_error')\n",
    "#performing grid search using 5 fold cross validation\n",
    "\n",
    "grid_search.fit(X_trainQB, y_trainQB)\n",
    "#fitting grid search\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "qbGBR = grid_search.best_estimator_\n",
    "#setting best estimator to 'qbGBR'\n",
    "\n",
    "y_predQB = qbGBR.predict(X_testQB)\n",
    "r2 = r2_score(y_testQB, y_predQB)\n",
    "print(\"R-squared:\", r2)\n",
    "mae = mean_absolute_error(y_testQB, y_predQB)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "#printing best parameters, r-squared, and mean absolute error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using 5-fold grid search cross validation in order to identify the best combination of hyperparameters for the model\n",
    "- Best parameters:\n",
    "'imputer__strategy': 'mean', 'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 5, 'model__min_samples_split': 2, 'model__n_estimators': 500, 'model__subsample': 0.8\n",
    "- R-squared\n",
    "    - Essentially the same value received prior to using grid search cross validation\n",
    "    - The r-squared value was 0.9241, meaning 92.41% of the variance in the data is explained by the model\n",
    "    - This value is high enough that it indicates the model has a good understanding of the variance within the data, and does not indicate overfitting\n",
    "- Mean squared error\n",
    "    - Much better MAE in comparison to the previous iteration\n",
    "        - Decrease of ~5 (6.53/1.81)\n",
    "    - On average, the models predictions deviate from the actual values by around 1.82 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running Back Gradient Boosting Model**\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a gradient boosting model to predict fantasy points for running backs. The first iteration will be built manually, and the second iteration will use 5-fold grid search cross validation in order to optimize hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>Week</th>\n",
       "      <th>did_not_play</th>\n",
       "      <th>Name_Encoded</th>\n",
       "      <th>Team_Encoded</th>\n",
       "      <th>Opponent_Encoded</th>\n",
       "      <th>Home/Away_Encoded</th>\n",
       "      <th>total_5_game_avg</th>\n",
       "      <th>passing_yds_5_game_avg</th>\n",
       "      <th>passing_td_5_game_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>season_rushing_td</th>\n",
       "      <th>season_total_avg</th>\n",
       "      <th>season_passing_yds_avg</th>\n",
       "      <th>season_passing_td_avg</th>\n",
       "      <th>season_receiving_rec_avg</th>\n",
       "      <th>season_receiving_yds_avg</th>\n",
       "      <th>season_receiving_td_avg</th>\n",
       "      <th>season_rushing_car_avg</th>\n",
       "      <th>season_rushing_yds_avg</th>\n",
       "      <th>season_fantasy_points_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2.700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>2.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>5.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>4.725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>4.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank  Week  did_not_play  Name_Encoded  Team_Encoded  Opponent_Encoded  \\\n",
       "0  65.0    17             0             0            11                20   \n",
       "1  42.0     1             0             0            11                 5   \n",
       "2  33.0     2             0             0            11                 1   \n",
       "3  58.0     3             0             0            11                22   \n",
       "4  73.0     4             0             0            11                10   \n",
       "\n",
       "   Home/Away_Encoded  total_5_game_avg  passing_yds_5_game_avg  \\\n",
       "0                  0             2.700                     0.0   \n",
       "1                  0             4.150                     0.0   \n",
       "2                  0             5.200                     0.0   \n",
       "3                  1             4.725                     0.0   \n",
       "4                  1             4.000                     0.0   \n",
       "\n",
       "   passing_td_5_game_avg  ...  season_rushing_td  season_total_avg  \\\n",
       "0                    0.0  ...                0.0             2.700   \n",
       "1                    0.0  ...                0.0             4.150   \n",
       "2                    0.0  ...                0.0             5.200   \n",
       "3                    0.0  ...                0.0             4.725   \n",
       "4                    0.0  ...                0.0             4.000   \n",
       "\n",
       "   season_passing_yds_avg  season_passing_td_avg  season_receiving_rec_avg  \\\n",
       "0                     0.0                    0.0                      0.00   \n",
       "1                     0.0                    0.0                      1.00   \n",
       "2                     0.0                    0.0                      1.00   \n",
       "3                     0.0                    0.0                      0.75   \n",
       "4                     0.0                    0.0                      0.60   \n",
       "\n",
       "   season_receiving_yds_avg  season_receiving_td_avg  season_rushing_car_avg  \\\n",
       "0                  0.000000                      0.0                7.000000   \n",
       "1                  8.500000                      0.0               10.000000   \n",
       "2                  8.333333                      0.0               11.666667   \n",
       "3                  6.250000                      0.0               11.500000   \n",
       "4                  5.000000                      0.0               10.200000   \n",
       "\n",
       "   season_rushing_yds_avg  season_fantasy_points_avg  \n",
       "0               27.000000                      2.700  \n",
       "1               23.000000                      4.150  \n",
       "2               33.666667                      5.200  \n",
       "3               33.500000                      4.725  \n",
       "4               29.000000                      4.000  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xrb = rbsM.select_dtypes(include = 'number').drop(columns=['TOTAL', 'Unnamed: 0'])\n",
    "\n",
    "yrb = rbsM['TOTAL']\n",
    "#assigning X and y\n",
    "\n",
    "Xrb.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assigning independent and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainRB, X_testRB, y_trainRB, y_testRB = train_test_split(Xrb, yrb, test_size= .80, random_state = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splitting up the data and allocating 80% of it to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***1st Iteration (not using hyperparameter tuning or grid search cross validation)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.4492447557926464\n",
      "R-squared: 0.9582130329022086\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "#initializing the gradient boosting regressor\n",
    "\n",
    "model.fit(X_trainRB, y_trainRB)\n",
    "#fitting the model to the training data\n",
    "\n",
    "y_predRB = model.predict(X_testRB)\n",
    "#getting prediction on the test set\n",
    "\n",
    "mse = mean_squared_error(y_testRB, y_predRB)\n",
    "r2 = r2_score(y_testRB, y_predRB)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "#getting prediction metrics on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fitting/testing the model manually (without hyperparameter tuning or grid search cross validation)\n",
    "- Parameters\n",
    "    - Number of estimators: 100\n",
    "    - Learning rate: 0.1\n",
    "    - Max Depth: 3\n",
    "- R-Squared\n",
    "    - Decent value of 0.96, meaning ~96% of the variance in the data is explained by the model\n",
    "    - This may indicate potential overfitting, however\n",
    "- Mean Absolute Error\n",
    "    - On average, the models predictions are off by ~2.4 points, which is a decent value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2nd Iteration (using hyperparameter tuning and grid search cross validation)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'imputer__strategy': 'most_frequent', 'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100, 'model__subsample': 1.0}\n",
      "R-squared: 0.9253561329214266\n",
      "Mean Absolute Error (MAE): 0.9595100507967558\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipe, paramGrid, cv=5, scoring='neg_mean_squared_error')\n",
    "#performing grid search using 5 fold cross validation\n",
    "\n",
    "grid_search.fit(X_trainRB, y_trainRB)\n",
    "#fitting grid search\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "rbGBR = grid_search.best_estimator_\n",
    "#setting best estimator to 'rbGBR'\n",
    "\n",
    "y_predRB = rbGBR.predict(X_testRB)\n",
    "r2 = r2_score(y_testRB, y_predRB)\n",
    "print(\"R-squared:\", r2)\n",
    "mae = mean_absolute_error(y_testRB, y_predRB)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "#printing best parameters, r-squared, and mean absolute error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using 5-fold grid search cross validation in order to identify the best combination of hyperparameters for the model\n",
    "- Best parameters: 'imputer__strategy': 'most_frequent', 'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100, 'model__subsample': 1.0\n",
    "    - Here we see a different combination of parameters (in comparison to the second iteration of the quarterback gradient boosting model) demonstrating the importance of position specific tuning for optimal performance\n",
    "- R-squared\n",
    "    - Essentially the same value received prior to using grid search cross validation\n",
    "    - The r-squared value was 0.93, meaning ~93% of the variance in the data is explained by the model\n",
    "    - This value is high enough that it indicates the model has a good understanding of the variance within the data, and does not indicate overfitting\n",
    "        - Performing the grid search cross validition has mitigated the issue of potential overfitting\n",
    "- Mean squared error\n",
    "    - Much better MAE in comparison to the previous iteration\n",
    "        - Decrease of ~5 (2.4/0.95)\n",
    "    - On average, the models predictions deviate from the actual values by around 0.95 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wide Receiver Gradient Boosting Model**\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a gradient boosting model to predict fantasy points for wide receivers. The first iteration will be built manually, and the second iteration will use 5-fold grid search cross validation in order to optimize hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>Week</th>\n",
       "      <th>did_not_play</th>\n",
       "      <th>Name_Encoded</th>\n",
       "      <th>Team_Encoded</th>\n",
       "      <th>Opponent_Encoded</th>\n",
       "      <th>Home/Away_Encoded</th>\n",
       "      <th>total_5_game_avg</th>\n",
       "      <th>passing_yds_5_game_avg</th>\n",
       "      <th>passing_td_5_game_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>season_rushing_td</th>\n",
       "      <th>season_total_avg</th>\n",
       "      <th>season_passing_yds_avg</th>\n",
       "      <th>season_passing_td_avg</th>\n",
       "      <th>season_receiving_rec_avg</th>\n",
       "      <th>season_receiving_yds_avg</th>\n",
       "      <th>season_receiving_td_avg</th>\n",
       "      <th>season_rushing_car_avg</th>\n",
       "      <th>season_rushing_yds_avg</th>\n",
       "      <th>season_fantasy_points_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>163.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>8.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>10.620000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.620000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>60.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.620000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank  Week  did_not_play  Name_Encoded  Team_Encoded  Opponent_Encoded  \\\n",
       "0   45.0    17             0             0            25                 0   \n",
       "1  163.0    18             0             0            25                23   \n",
       "2   21.0     1             0             0            25                21   \n",
       "3   69.5     2             0             0            25                20   \n",
       "4   11.0     3             0             0            25                29   \n",
       "\n",
       "   Home/Away_Encoded  total_5_game_avg  passing_yds_5_game_avg  \\\n",
       "0                  1          9.300000                     0.0   \n",
       "1                  0          4.600000                     0.0   \n",
       "2                  0          8.033333                     0.0   \n",
       "3                  1          7.750000                     0.0   \n",
       "4                  0         10.620000                     0.0   \n",
       "\n",
       "   passing_td_5_game_avg  ...  season_rushing_td  season_total_avg  \\\n",
       "0                    0.0  ...                0.0          9.300000   \n",
       "1                    0.0  ...                0.0          4.600000   \n",
       "2                    0.0  ...                0.0          8.033333   \n",
       "3                    0.0  ...                0.0          7.750000   \n",
       "4                    0.0  ...                0.0         10.620000   \n",
       "\n",
       "   season_passing_yds_avg  season_passing_td_avg  season_receiving_rec_avg  \\\n",
       "0                     0.0                    0.0                       4.0   \n",
       "1                     0.0                    0.0                       2.5   \n",
       "2                     0.0                    0.0                       4.0   \n",
       "3                     0.0                    0.0                       4.0   \n",
       "4                     0.0                    0.0                       5.0   \n",
       "\n",
       "   season_receiving_yds_avg  season_receiving_td_avg  season_rushing_car_avg  \\\n",
       "0                      53.0                      0.0                     0.0   \n",
       "1                      31.0                      0.0                     0.0   \n",
       "2                      47.0                      0.0                     0.0   \n",
       "3                      42.5                      0.0                     0.0   \n",
       "4                      60.2                      0.0                     0.0   \n",
       "\n",
       "   season_rushing_yds_avg  season_fantasy_points_avg  \n",
       "0                     0.0                   9.300000  \n",
       "1                     0.0                   4.600000  \n",
       "2                     0.0                   8.033333  \n",
       "3                     0.0                   7.750000  \n",
       "4                     0.0                  10.620000  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xwr = wrsM.select_dtypes(include = 'number').drop(columns=['TOTAL', 'Unnamed: 0'])\n",
    "\n",
    "ywr = wrsM['TOTAL']\n",
    "#assigning X and y\n",
    "\n",
    "Xwr.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assigning independent and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainWR, X_testWR, y_trainWR, y_testWR = train_test_split(Xwr, ywr, test_size= .80, random_state = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splitting up the data and allocating 80% of it to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***1st Iteration (not using hyperparameter tuning and grid search cross validation)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.9845284394475657\n",
      "R-squared: 0.9679491945510705\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "#initializing the gradient boosting regressor\n",
    "\n",
    "model.fit(X_trainWR, y_trainWR)\n",
    "#fitting the model to the training data\n",
    "\n",
    "y_predWR = model.predict(X_testWR)\n",
    "#getting prediction on the test set\n",
    "\n",
    "mse = mean_squared_error(y_testWR, y_predWR)\n",
    "r2 = r2_score(y_testWR, y_predWR)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "#getting prediction metrics on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fitting/testing the model manually (without hyperparameter tuning or grid search cross validation)\n",
    "- Parameters\n",
    "    - Number of estimators: 100\n",
    "    - Learning rate: 0.1\n",
    "    - Max Depth: 3\n",
    "- R-Squared\n",
    "    - Moderate value 0.97, meaning ~97% of the variance in the data is explained by the model\n",
    "    - While a high percentage of the variance is explained by the model, this may indicate overfitting\n",
    "- Mean Absolute Error\n",
    "    - On average, the models predictions are off by ~1.98 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2nd Iteration (using hyperparameter tuning and grid search cross validation)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'imputer__strategy': 'most_frequent', 'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 500, 'model__subsample': 1.0}\n",
      "R-squared: 0.9700842110254662\n",
      "Mean Absolute Error (MAE): 0.6255660445604516\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipe, paramGrid, cv=5, scoring='neg_mean_squared_error')\n",
    "#performing grid search using 5 fold cross validation\n",
    "\n",
    "grid_search.fit(X_trainWR, y_trainWR)\n",
    "#fitting grid search\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "wrGBR = grid_search.best_estimator_\n",
    "#setting best estimator to 'wrGBR'\n",
    "\n",
    "y_predWR = wrGBR.predict(X_testWR)\n",
    "r2 = r2_score(y_testWR, y_predWR)\n",
    "print(\"R-squared:\", r2)\n",
    "mae = mean_absolute_error(y_testWR, y_predWR)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "#printing best parameters, r-squared, and mean absolute error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using 5-fold grid search cross validation in order to identify the best combination of hyperparameters for the model\n",
    "- Best parameters: 'imputer__strategy': 'constant', 'model__learning_rate': 0.2, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 200, 'model__subsample': 0.8\n",
    "    - Once again we see a different combination of parameters, demonstrating the importance of position specific tuning for optimal performance\n",
    "- R-squared\n",
    "    - Essentially the same value received prior to using grid search cross validation\n",
    "    - The r-squared value was 0.97, meaning ~97% of the variance in the data is explained by the model\n",
    "    - This value is high enough that it could indicate overfitting\n",
    "        - Performing the grid search cross validition does not seem to have mitigated the issue of potential overfitting\n",
    "- Mean squared error\n",
    "    - Much better MAE in comparison to the previous iteration\n",
    "        - Decrease of ~5 (1.9/0.6)\n",
    "    - On average, the models predictions deviate from the actual values by around 0.62 points\n",
    "- Metrics seem to indicate at least some overfitting\n",
    "    - Very high r-sqaured, very low mean absolute error\n",
    "        - The mean absolute error of 0.63 is not realistic due to the variability of real life player performance\n",
    "    - Grid search cross validation did not mitigate this issue as we saw with the previous two models\n",
    "    - The baseline model, ridge regression, may be the better model for the wide receiver position\n",
    "    - This, once again, highlights the importance of modeling positions differently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tight End Gradient Boosting Model**\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a gradient boosting model to predict fantasy points for tight ends. The first iteration will be built manually, and the second iteration will use 5-fold grid search cross validation in order to optimize hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>Week</th>\n",
       "      <th>did_not_play</th>\n",
       "      <th>Name_Encoded</th>\n",
       "      <th>Team_Encoded</th>\n",
       "      <th>Opponent_Encoded</th>\n",
       "      <th>Home/Away_Encoded</th>\n",
       "      <th>total_5_game_avg</th>\n",
       "      <th>passing_yds_5_game_avg</th>\n",
       "      <th>passing_td_5_game_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>season_rushing_td</th>\n",
       "      <th>season_total_avg</th>\n",
       "      <th>season_passing_yds_avg</th>\n",
       "      <th>season_passing_td_avg</th>\n",
       "      <th>season_receiving_rec_avg</th>\n",
       "      <th>season_receiving_yds_avg</th>\n",
       "      <th>season_receiving_td_avg</th>\n",
       "      <th>season_rushing_car_avg</th>\n",
       "      <th>season_rushing_yds_avg</th>\n",
       "      <th>season_fantasy_points_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.5</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>3.350000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.350000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.680000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank  Week  did_not_play  Name_Encoded  Team_Encoded  Opponent_Encoded  \\\n",
       "0  48.5    17             0             0             9                16   \n",
       "1  40.0    18             0             0             9                18   \n",
       "2  10.0     1             0             0             9                18   \n",
       "3  76.0     2             0             0             9                31   \n",
       "4  79.0     3             0             0             9                19   \n",
       "\n",
       "   Home/Away_Encoded  total_5_game_avg  passing_yds_5_game_avg  \\\n",
       "0                  1          1.900000                     0.0   \n",
       "1                  0          2.500000                     0.0   \n",
       "2                  1          4.466667                     0.0   \n",
       "3                  1          3.350000                     0.0   \n",
       "4                  0          2.680000                     0.0   \n",
       "\n",
       "   passing_td_5_game_avg  ...  season_rushing_td  season_total_avg  \\\n",
       "0                    0.0  ...                0.0          1.900000   \n",
       "1                    0.0  ...                0.0          2.500000   \n",
       "2                    0.0  ...                0.0          4.466667   \n",
       "3                    0.0  ...                0.0          3.350000   \n",
       "4                    0.0  ...                0.0          2.680000   \n",
       "\n",
       "   season_passing_yds_avg  season_passing_td_avg  season_receiving_rec_avg  \\\n",
       "0                     0.0                    0.0                  1.000000   \n",
       "1                     0.0                    0.0                  1.000000   \n",
       "2                     0.0                    0.0                  2.333333   \n",
       "3                     0.0                    0.0                  1.750000   \n",
       "4                     0.0                    0.0                  1.400000   \n",
       "\n",
       "   season_receiving_yds_avg  season_receiving_td_avg  season_rushing_car_avg  \\\n",
       "0                  9.000000                      0.0                     0.0   \n",
       "1                 15.000000                      0.0                     0.0   \n",
       "2                 21.333333                      0.0                     0.0   \n",
       "3                 16.000000                      0.0                     0.0   \n",
       "4                 12.800000                      0.0                     0.0   \n",
       "\n",
       "   season_rushing_yds_avg  season_fantasy_points_avg  \n",
       "0                     0.0                   1.900000  \n",
       "1                     0.0                   2.500000  \n",
       "2                     0.0                   4.466667  \n",
       "3                     0.0                   3.350000  \n",
       "4                     0.0                   2.680000  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xte = tesM.select_dtypes(include = 'number').drop(columns=['TOTAL', 'Unnamed: 0'])\n",
    "\n",
    "yte = tesM['TOTAL']\n",
    "#assigning X and y\n",
    "\n",
    "Xte.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assigning independent and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainTE, X_testTE, y_trainTE, y_testTE = train_test_split(Xte, yte, test_size= .80, random_state = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splitting up the data and allocating 80% of it to training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***1st Iteration (not using hyperparameter tuning and grid search cross validation)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.4868797397117024\n",
      "R-squared: 0.9506697323171321\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "#initializing the gradient boosting regressor\n",
    "\n",
    "model.fit(X_trainTE, y_trainTE)\n",
    "#fitting the model to the training data\n",
    "\n",
    "y_predTE = model.predict(X_testTE)\n",
    "#getting prediction on the test set\n",
    "\n",
    "mse = mean_squared_error(y_testTE, y_predTE)\n",
    "r2 = r2_score(y_testTE, y_predTE)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "#getting prediction metrics on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fitting/testing the model manually (without hyperparameter tuning or grid search cross validation)\n",
    "- Parameters\n",
    "    - Number of estimators: 100\n",
    "    - Learning rate: 0.1\n",
    "    - Max Depth: 3\n",
    "- R-Squared\n",
    "    - Solid value .951, meaning ~95% of the variance in the data is explained by the model\n",
    "    - While a high percentage of the variance is explained by the model, this could potentially indicate overfitting\n",
    "- Mean Absolute Error\n",
    "    - On average, the models predictions are off by ~1.49 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2nd Iteration (using hyperparameter tuning and grid search cross validation)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'imputer__strategy': 'constant', 'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 500, 'model__subsample': 0.8}\n",
      "R-squared: 0.9465175833049173\n",
      "Mean Absolute Error (MAE): 0.5997776885067116\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipe, paramGrid, cv=5, scoring='neg_mean_squared_error')\n",
    "#performing grid search using 5 fold cross validation\n",
    "\n",
    "grid_search.fit(X_trainTE, y_trainTE)\n",
    "#fitting grid search\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "teGBR = grid_search.best_estimator_\n",
    "#setting best estimator to 'wrGBR'\n",
    "\n",
    "y_predTE = teGBR.predict(X_testTE)\n",
    "r2 = r2_score(y_testTE, y_predTE)\n",
    "print(\"R-squared:\", r2)\n",
    "mae = mean_absolute_error(y_testTE, y_predTE)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "#printing best parameters, r-squared, and mean absolute error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using 5-fold grid search cross validation in order to identify the best combination of hyperparameters for the model\n",
    "- Best parameters: \n",
    "- R-squared\n",
    "    - Essentially the same value received prior to using grid search cross validation\n",
    "    - The r-squared value is .947, meaning ~94% of the variance in the data is explained by the model\n",
    "    - This value is high enough that it indicates the model has a good understanding of the variance within the data, and does not indicate overfitting\n",
    "        - Performing the grid search cross validition has mitigated the issue of potential overfitting\n",
    "- Mean squared error\n",
    "    - Lower MAE in comparison to the previous iteration\n",
    "        - Decrease of ~0.4 (0.95/0.59)\n",
    "    - On average, the models predictions deviate from the actual values by ~0.59 points\n",
    "    - This value isnt great, due to the fact that this is fairly unrealistic due to the variability of players performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing for Overfitting**\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing models to determine whether or not their training values are better than testing values, indicating overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quarterbacks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MAE (Quarterbacks): 0.7934786820656909\n",
      "Test MAE (Quarterbacks): 1.819497914233167\n",
      "Potential Overfitting. Training MAE: 0.7934786820656909, Test MAE: 1.819497914233167\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = qbGBR.predict(X_trainQB) \n",
    "train_mae = mean_absolute_error(y_trainQB, y_train_pred)\n",
    "print(\"Training MAE (Quarterbacks):\", train_mae)\n",
    "#Calculating Training Set MAE\n",
    "\n",
    "y_test_pred = qbGBR.predict(X_testQB)\n",
    "test_mae = mean_absolute_error(y_testQB, y_test_pred)\n",
    "print(\"Test MAE (Quarterbacks):\", test_mae)\n",
    "#Calculating Test Set MAE\n",
    "\n",
    "if train_mae < test_mae:\n",
    "    print(f\"Potential Overfitting. Training MAE: {train_mae}, Test MAE: {test_mae}\")\n",
    "else:\n",
    "    print(\"Model appears to generalize well.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running Backs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MAE (Running Backs): 0.0014423242049603\n",
      "Test MAE (Running Backs): 0.9595100507967558\n",
      "Potential Overfitting. Training MAE: 0.0014423242049603, Test MAE: 0.9595100507967558\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = rbGBR.predict(X_trainRB) \n",
    "train_mae = mean_absolute_error(y_trainRB, y_train_pred)\n",
    "print(\"Training MAE (Running Backs):\", train_mae)\n",
    "#Calculating Training Set MAE\n",
    "\n",
    "y_test_pred = rbGBR.predict(X_testRB)\n",
    "test_mae = mean_absolute_error(y_testRB, y_test_pred)\n",
    "print(\"Test MAE (Running Backs):\", test_mae)\n",
    "#Calculating Test Set MAE\n",
    "\n",
    "if train_mae < test_mae:\n",
    "    print(f\"Potential Overfitting. Training MAE: {train_mae}, Test MAE: {test_mae}\")\n",
    "else:\n",
    "    print(\"Model appears to generalize well.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wide Receivers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MAE (Wide Receivers): 0.06713637908271224\n",
      "Test MAE (Wide Receivers): 0.6255660445604516\n",
      "Potential Overfitting. Training MAE: 0.06713637908271224, Test MAE: 0.6255660445604516\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = wrGBR.predict(X_trainWR) \n",
    "train_mae = mean_absolute_error(y_trainWR, y_train_pred)\n",
    "print(\"Training MAE (Wide Receivers):\", train_mae)\n",
    "#Calculating Training Set MAE\n",
    "\n",
    "y_test_pred = wrGBR.predict(X_testWR)\n",
    "test_mae = mean_absolute_error(y_testWR, y_test_pred)\n",
    "print(\"Test MAE (Wide Receivers):\", test_mae)\n",
    "#Calculating Test Set MAE\n",
    "\n",
    "if train_mae < test_mae:\n",
    "    print(f\"Potential Overfitting. Training MAE: {train_mae}, Test MAE: {test_mae}\")\n",
    "else:\n",
    "    print(\"Model appears to generalize well.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tight Ends**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MAE (Tight Ends): 0.0003543353333677896\n",
      "Test MAE (Tight Ends): 0.5997776885067116\n",
      "Potential Overfitting. Training MAE: 0.0003543353333677896, Test MAE: 0.5997776885067116\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = teGBR.predict(X_trainTE) \n",
    "train_mae = mean_absolute_error(y_trainTE, y_train_pred)\n",
    "print(\"Training MAE (Tight Ends):\", train_mae)\n",
    "#Calculating Training Set MAE\n",
    "\n",
    "y_test_pred = teGBR.predict(X_testTE)\n",
    "test_mae = mean_absolute_error(y_testTE, y_test_pred)\n",
    "print(\"Test MAE (Tight Ends):\", test_mae)\n",
    "#Calculating Test Set MAE\n",
    "\n",
    "if train_mae < test_mae:\n",
    "    print(f\"Potential Overfitting. Training MAE: {train_mae}, Test MAE: {test_mae}\")\n",
    "else:\n",
    "    print(\"Model appears to generalize well.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is significant overfitting occurring in each model. This suggests that the model has essentially \"memorized\" the patterns in the training data, including noise or irrelevant details, rather than learning generalizable insights about the underlying structure of the data.\n",
    "\n",
    "A test MAE of ~0.6, for example, means the model is consistently predicting fantasy points within a margin of less than one point. Given the unpredictable nature of fantasy performance, even for top-tier players, this level of accuracy is extremely unlikely without some form of overfitting.\n",
    "\n",
    "The presence of significant overfitting, even after applying robust techniques like 5-fold grid search cross-validation and hyperparameter tuning, indicates that there may be some sort of underlying issue, like some form of data-leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remodeling without Data-Leakage**\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there may be data-leakage occuring with could be leading to the overfitting that is occuring in each model. Features such as 'TOTAL', 'Unnamed: 0', 'total_5_game_avg', 'season_total_avg', and 'season_fantasy_points_avg', could be giving the model too much information and allowing it to 'cheat', essentially. This would explain the extremely low, and unrealistic, mean absolute error values. The subsequent models will be the exact same as the previous manual iterations, except the aforementioned features will be removed from the list of independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quarterback Gradient Boosting Model (trying to avoid data leakage)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.804761476824994\n",
      "R-squared: 0.9270652215266868\n"
     ]
    }
   ],
   "source": [
    "Xqb = qbsM.select_dtypes(include = 'number').drop(columns=['TOTAL', 'Unnamed: 0', 'total_5_game_avg', 'season_total_avg', 'season_fantasy_points_avg', 'season_total', 'season_passing_yds', 'season_receiving_rec', 'season_receiving_yds', 'season_receiving_td', 'season_rushing_yds', 'season_rushing_td', 'season_total_avg', 'season_passing_yds_avg', 'season_passing_td_avg', 'season_receiving_rec_avg', 'season_receiving_td_avg', 'season_rushing_car_avg', 'season_rushing_yds_avg', 'season_fantasy_points_avg'])\n",
    "\n",
    "yqb = qbsM['TOTAL']\n",
    "#assigning X and y\n",
    "\n",
    "X_trainQB, X_testQB, y_trainQB, y_testQB = train_test_split(Xqb, yqb, test_size= .80, random_state = 14)\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "#initializing the gradient boosting regressor\n",
    "\n",
    "model.fit(X_trainQB, y_trainQB)\n",
    "#fitting the model to the training data\n",
    "\n",
    "y_predQB = model.predict(X_testQB)\n",
    "#getting prediction on the test set\n",
    "\n",
    "mae = mean_absolute_error(y_testQB, y_predQB)\n",
    "r2 = r2_score(y_testQB, y_predQB)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "#getting prediction metrics on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fitting/testing the model manually, while removing features that could be leading to data-leakage\n",
    "- R-Squared\n",
    "    - Solid value of .92, meaning ~92% of the variance in the data is explained by the model\n",
    "    - While a high percentage of the variance is explained by the model, this is not high enough to indicate overfitting or data leakage\n",
    "- Mean Absolute Error\n",
    "    - On average, the models predictions are off by ~1.8 points\n",
    "    - This is a realistic value, similar to the original mean absolute error of 1.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running Back Gradient Boosting Model (trying to avoid data leakage)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.7377080004288752\n",
      "R-squared: 0.9607680205152382\n"
     ]
    }
   ],
   "source": [
    "Xrb = rbsM.select_dtypes(include = 'number').drop(columns=['TOTAL', 'Unnamed: 0', 'total_5_game_avg', 'season_total_avg', 'season_fantasy_points_avg', 'season_total', 'season_passing_yds', 'season_receiving_rec', 'season_receiving_yds', 'season_receiving_td', 'season_rushing_yds', 'season_rushing_td', 'season_total_avg', 'season_passing_yds_avg', 'season_passing_td_avg', 'season_receiving_rec_avg', 'season_receiving_td_avg', 'season_rushing_car_avg', 'season_rushing_yds_avg', 'season_fantasy_points_avg'])\n",
    "\n",
    "yrb = rbsM['TOTAL']\n",
    "#assigning X and y\n",
    "\n",
    "X_trainRB, X_testRB, y_trainRB, y_testRB = train_test_split(Xrb, yrb, test_size= .80, random_state = 14)\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "#initializing the gradient boosting regressor\n",
    "\n",
    "model.fit(X_trainRB, y_trainRB)\n",
    "#fitting the model to the training data\n",
    "\n",
    "y_predRB = model.predict(X_testRB)\n",
    "#getting prediction on the test set\n",
    "\n",
    "mae = mean_absolute_error(y_testRB, y_predRB)\n",
    "r2 = r2_score(y_testRB, y_predRB)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "#getting prediction metrics on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fitting/testing the model manually, while removing features that could be leading to data-leakage\n",
    "- R-Squared\n",
    "    - High value of .961, meaning ~96% of the variance in the data is explained by the model\n",
    "    - A high percentage of the variance is explained by the model, this is still indicates overfitting\n",
    "- Mean Absolute Error\n",
    "    - On average, the models predictions are off by ~0.7 points\n",
    "    - This is a very unrealistic value, and still indicates significant overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wide Receiver Gradient Boosting Model (trying to avoid data leakage)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.6609763102116485\n",
      "R-squared: 0.969035015518867\n"
     ]
    }
   ],
   "source": [
    "Xwr = wrsM.select_dtypes(include = 'number').drop(columns=['TOTAL', 'Unnamed: 0', 'total_5_game_avg', 'season_total_avg', 'season_fantasy_points_avg', 'season_total', 'season_passing_yds', 'season_receiving_rec', 'season_receiving_yds', 'season_receiving_td', 'season_rushing_yds', 'season_rushing_td', 'season_total_avg', 'season_passing_yds_avg', 'season_passing_td_avg', 'season_receiving_rec_avg', 'season_receiving_td_avg', 'season_rushing_car_avg', 'season_rushing_yds_avg', 'season_fantasy_points_avg'])\n",
    "\n",
    "ywr = wrsM['TOTAL']\n",
    "#assigning X and y\n",
    "\n",
    "X_trainWR, X_testWR, y_trainWR, y_testWR = train_test_split(Xwr, ywr, test_size= .80, random_state = 14)\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "#initializing the gradient boosting regressor\n",
    "\n",
    "model.fit(X_trainWR, y_trainWR)\n",
    "#fitting the model to the training data\n",
    "\n",
    "y_predWR = model.predict(X_testWR)\n",
    "#getting prediction on the test set\n",
    "\n",
    "mae = mean_absolute_error(y_testWR, y_predWR)\n",
    "r2 = r2_score(y_testWR, y_predWR)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "#getting prediction metrics on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fitting/testing the model manually, while removing features that could be leading to data-leakage\n",
    "- R-Squared\n",
    "    - High value of .967, meaning ~96% of the variance in the data is explained by the model\n",
    "    - A high percentage of the variance is explained by the model, this is still indicates overfitting\n",
    "- Mean Absolute Error\n",
    "    - On average, the models predictions are off by ~0.6 points\n",
    "    - This is a very unrealistic value, and still indicates significant overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tight End Gradient Boosting Model (trying to avoid data leakage)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.7221431212135927\n",
      "R-squared: 0.9391220374638384\n"
     ]
    }
   ],
   "source": [
    "Xte = tesM.select_dtypes(include = 'number').drop(columns=['TOTAL', 'Unnamed: 0', 'total_5_game_avg', 'season_total_avg', 'season_fantasy_points_avg', 'season_total', 'season_passing_yds', 'season_receiving_rec', 'season_receiving_yds', 'season_receiving_td', 'season_rushing_yds', 'season_rushing_td', 'season_total_avg', 'season_passing_yds_avg', 'season_passing_td_avg', 'season_receiving_rec_avg', 'season_receiving_td_avg', 'season_rushing_car_avg', 'season_rushing_yds_avg', 'season_fantasy_points_avg'])\n",
    "\n",
    "yte = tesM['TOTAL']\n",
    "#assigning X and y\n",
    "\n",
    "X_trainTE, X_testTE, y_trainTE, y_testTE = train_test_split(Xte, yte, test_size= .80, random_state = 14)\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.05, max_depth=2, min_samples_split=10, subsample=0.8, random_state=42)\n",
    "#initializing the gradient boosting regressor\n",
    "\n",
    "model.fit(X_trainTE, y_trainTE)\n",
    "#fitting the model to the training data\n",
    "\n",
    "y_predTE = model.predict(X_testTE)\n",
    "#getting prediction on the test set\n",
    "\n",
    "mae = mean_absolute_error(y_testTE, y_predTE)\n",
    "r2 = r2_score(y_testTE, y_predTE)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "#getting prediction metrics on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fitting/testing the model manually, while removing features that could be leading to data-leakage\n",
    "- Changing parameters to try and mitigate overfitting\n",
    "- R-Squared\n",
    "    - High value of .945, meaning ~95% of the variance in the data is explained by the model\n",
    "    - A high percentage of the variance is explained by the model, this is still indicates overfitting\n",
    "- Mean Absolute Error\n",
    "    - On average, the models predictions are off by ~0.6 points\n",
    "    - This is a very unrealistic value, and still indicates significant overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after removing features that could potentially lead to data leakage, such as cumulative averages (season_total_avg, season_fantasy_points_avg), the model continues to produce values that are highly unrealistic given the inherent variability in player performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advanced Modeling Metric Analysis**\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evalData = {\n",
    "    'Position': ['Quarterback', 'Running Back', 'Wide Receiver', 'Tight End'],\n",
    "    'R-squared': [0.9242, 0.9253, 0.970084, 0.9465],\n",
    "    'MAE': [1.819, 0.959, 0.6255, 0.599]\n",
    "}\n",
    "#creating dictionary wiht evaluation data\n",
    "\n",
    "evaldf = pd.DataFrame(evalData)\n",
    "#turning it into a dataframe\n",
    "\n",
    "df_melted = evaldf.melt(id_vars='Position', var_name='Metric', value_name='Value')\n",
    "#melting the dataframe to use seaborn\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df_melted, x='Position', y='Value', hue='Metric', palette='colorblind')\n",
    "plt.title('Gradient Boosting Performance by Position', fontsize=16)\n",
    "plt.xlabel('Positions', fontsize=12)\n",
    "plt.ylabel('Values', fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.legend(title='Metric', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quarterbacks:\n",
    "- R-squared (0.9242): This high value indicates the model captures most of the variance in quarterback fantasy points\n",
    "- MAE (1.819): This MAE is a much more realistic value, especially in comparison to the other models\n",
    "\n",
    "Running Backs:\n",
    "- R-squared (0.9253): Good value at a glance, however we know overfitting is occuring\n",
    "- MAE (0.959): Extremely low, and unrealistic MAE\n",
    "\n",
    "Wide Receivers:\n",
    "- R-squared (0.970084): The highest R-squared among positions\n",
    "- MAE (0.6255): Extremely low, and unrealistic MAE\n",
    "    - Along withthe high R-squared, it is clear the model is overfitting, as wide receiver performance can vary significantly depending on game conditions\n",
    "\n",
    "Tight Ends:\n",
    "- R-squared (0.9465): This is another strong value at a glance, however we know overfitting is occuring\n",
    "- MAE (0.599): The lowest MAE among all positions\n",
    "    - This reflects the overfitting occurring, as tight end performance is often highly variable due to game scripts and reliance on touchdowns\n",
    "\n",
    "\n",
    "Observations:\n",
    "\n",
    "The extremely low MAE for wide receivers and tight ends, combined with their high R-squared, indicates overfitting, as these positions tend to have more variability in performance than reflected in the metrics. For quarterbacks, the MAE values align more closely with expectations, as their performance is generally more stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advanced Modeling Conclusion**\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we explored the use of Gradient Boosting models for predicting fantasy points for tight ends. Despite implementing advanced techniques such as Grid Search Cross-Validation and extensive hyperparameter tuning, the models exhibited significant overfitting. The training MAE was extremely low, suggesting the model had effectively memorized the training data, while the test MAE, although higher, was still unrealistically low given the inherent variability in player performance.\n",
    "\n",
    "This overfitting indicates a mismatch between the complexity of the Gradient Boosting model and the nature of the dataset. NFL player performance is highly variable and influenced by external factors (e.g., game script, injuries, and touchdowns) that are difficult to model this accurately. As a result, the Gradient Boosting model's flexibility and capacity to capture intricate patterns likely lead to it overfitting the training data rather than generalizing well to unseen data.\n",
    "\n",
    "Given this behavior, it appears that the simpler baseline model (Ridge Regression) may be more suitable for this problem. Ridge regression models, with their inherent regularization and reduced complexity, are less prone to overfitting and often provide more realistic and generalizable predictions in situations where data variability and noise are significant factors.\n",
    "\n",
    "Moving forward, further exploration of baseline models and simpler approaches should be prioritized, as they are likely to yield better results for this dataset. Additionally, further efforts could be directed toward improving feature engineering, carefully handling potential data leakage, and revisiting the model evaluation strategy to ensure reliable and actionable insights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
